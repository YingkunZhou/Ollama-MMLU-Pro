diff --git a/examples/imatrix/imatrix.cpp b/examples/imatrix/imatrix.cpp
index 2e03a4a0..97025567 100644
--- a/examples/imatrix/imatrix.cpp
+++ b/examples/imatrix/imatrix.cpp
@@ -37,8 +37,16 @@ static void print_usage(int argc, char ** argv, const gpt_params & params) {
     LOG_TEE("\n");
 }
 
+#define DUMP_ACTIVATION 0
+#define DUMP_THRESHOLDS 1
 struct Stats {
     std::vector<float> values;
+#if DUMP_ACTIVATION || DUMP_THRESHOLDS
+    std::vector<float> activations;
+#endif
+#if DUMP_THRESHOLDS
+    std::vector<float> top_k;
+#endif
     std::vector<int> counts;
     int ncall = 0;
     int n_as = 1;
@@ -164,6 +172,29 @@ void IMatrixCollector::print_layer_importance() {
     //}
 }
 
+#if DUMP_THRESHOLDS
+void bucket_process(const std::vector<float>& arr, std::vector<float>& top_k) {
+    const size_t CHUNK = 1024;
+    size_t N = arr.size();
+    size_t num_groups = N / CHUNK;
+
+    float min_512 = std::numeric_limits<float>::infinity();
+    float min_256 = std::numeric_limits<float>::infinity();
+
+    for (size_t g = 0; g < num_groups; g++) {
+        const float* base = arr.data() + g * CHUNK;
+
+        float tmp[CHUNK];
+        std::copy(base, base + CHUNK, tmp);
+
+        int pos_median = CHUNK/2;
+        std::nth_element(tmp, tmp + pos_median, tmp + CHUNK);
+        float median = tmp[pos_median];
+        top_k.push_back(median);
+    }
+}
+#endif
+
 bool IMatrixCollector::collect_imatrix(struct ggml_tensor * t, bool ask, void * user_data) {
     GGML_UNUSED(user_data);
 
@@ -341,12 +372,21 @@ bool IMatrixCollector::collect_imatrix(struct ggml_tensor * t, bool ask, void *
             // Hence, the storage we need is src0->ne[0]*src0->ne[2].
             e.values.resize(src0->ne[0]*src0->ne[2], 0);
             e.counts.resize(src0->ne[0]*src0->ne[2], 0);
+#if DUMP_ACTIVATION
+            e.activations.resize(src1->ne[0]*src1->ne[1]);
+#elif DUMP_THRESHOLDS
+            e.activations.resize(src1->ne[0]);
+            e.top_k.clear();
+#endif
         }
         else if (e.values.size() != (size_t)(src0->ne[0]*src0->ne[2])) {
             fprintf(stderr, "Oops: inconsistent size for %s (%d vs %d)\n", wname.c_str(), (int)e.values.size(), (int)src1->ne[0]);
             exit(1); //GGML_ABORT("fatal error");
         }
         ++e.ncall;
+#if DUMP_THRESHOLDS
+        e.activations.assign(e.activations.size(), 0.0f);
+#endif
         if (m_params.verbosity > 1) {
             printf("%s[%d]: %32s, %s, %5d x %5d, %d\n", __func__, m_last_call, wname.c_str(), ggml_op_name(t->op), (int)src1->ne[0], (int)src1->ne[1], (int)src1->type);
         }
@@ -357,14 +397,30 @@ bool IMatrixCollector::collect_imatrix(struct ggml_tensor * t, bool ask, void *
             auto counts = e.counts.data() + i02*src0->ne[0];
             for (int i11 = 0; i11 < (int)src1->ne[1]; ++i11) {
                 const float * x = (const float *)((const char *)data + i11*src1->nb[1] + i12*src1->nb[2]);
+#if DUMP_ACTIVATION
+                auto activations = e.activations.data() + i11*src1->ne[0];
+#elif DUMP_THRESHOLDS
+                auto activations = e.activations.data();
+#endif
                 for (int j = 0; j < (int)src1->ne[0]; ++j) {
                     values[j] += x[j]*x[j];
+#if DUMP_ACTIVATION
+                    activations[j] = x[j]*x[j];
+#elif DUMP_THRESHOLDS
+                    activations[j] += x[j]*x[j];
+#endif
                     counts[j]++;
                     if (!std::isfinite(values[j])) {
                         fprintf(stderr, "%f detected in %s\n", e.values[j], wname.c_str());
                         exit(1);
                     }
                 }
+#if DUMP_THRESHOLDS
+                if (i11%5 == 4) {
+                    bucket_process(e.activations, e.top_k);
+                    e.activations.assign(e.activations.size(), 0.0f);
+                }
+#endif
             }
         }
         if (e.ncall > m_last_call) {
@@ -482,6 +538,21 @@ void IMatrixCollector::save_imatrix(int ncall) const {
                 tmp[i] = (stat.values[i] / static_cast<float>(stat.counts[i])) * static_cast<float>(stat.ncall);
             }
             out.write((const char*)tmp.data(), nval*sizeof(float));
+#if DUMP_ACTIVATION
+            int nact = stat.activations.size();
+            out.write((const char *) &nact, sizeof(nact));
+            out.write((const char*)stat.activations.data(), nact*sizeof(float));
+#elif DUMP_THRESHOLDS
+            size_t index0 = std::ceil(0.1 * stat.top_k.size());
+            std::vector<float> temp0 = stat.top_k;
+            std::nth_element(temp0.begin(), temp0.begin() + index0, temp0.end());
+            out.write((const char *)&temp0[index0], sizeof(float));
+
+            size_t index1 = std::ceil(0.9 * stat.top_k.size());
+            std::vector<float> temp1 = stat.top_k;
+            std::nth_element(temp1.begin(), temp1.begin() + index1, temp1.end());
+            out.write((const char *)&temp1[index1], sizeof(float));
+#endif
         }
     }
 
